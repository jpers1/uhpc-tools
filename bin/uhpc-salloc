#!/usr/bin/env bash
#
# uhpc-salloc: Allocate a node, spawn multiple shells, detach in background.
#
# Usage: uhpc-salloc [NUM_SHELLS] [<any Slurm options>]
# Defaults:
#   NUM_SHELLS=2
#   --partition=compute (unless user provides --partition=xxx)
#   --time=1:00:00 (unless user provides --time=xxx)
#   -N1 (one node)
#
# Example:
#   uhpc-salloc 3 --partition=gpu --time=2:00:00 --gres=gpu:2 --mem=120G ...
#
# After it spawns shells, it goes into the background so your terminal is freed.
# It will print the jobID and instructions for how to attach with uhpc-login.

set -e

# Defaults
DEFAULT_NUM_SHELLS=2
DEFAULT_PARTITION="compute"
DEFAULT_TIME="1:00:00"

# Parse arguments
NUM_SHELLS="$DEFAULT_NUM_SHELLS"
EXTRA_ARGS=()

PARTITION_SPECIFIED=false
TIME_SPECIFIED=false

for arg in "$@"; do
  # If it's purely numeric, treat as NUM_SHELLS:
  if [[ "$arg" =~ ^[0-9]+$ ]]; then
    NUM_SHELLS="$arg"
    continue
  fi

  # Detect if user explicitly set partition or time
  if [[ "$arg" == --partition=* ]]; then
    PARTITION_SPECIFIED=true
  elif [[ "$arg" == --time=* ]]; then
    TIME_SPECIFIED=true
  fi

  # Pass all non-numeric args to salloc
  EXTRA_ARGS+=("$arg")
done

# If user didn't specify partition, add the default
if ! $PARTITION_SPECIFIED; then
  EXTRA_ARGS+=( "--partition=$DEFAULT_PARTITION" )
fi

# If user didn't specify time, add the default
if ! $TIME_SPECIFIED; then
  EXTRA_ARGS+=( "--time=$DEFAULT_TIME" )
fi

echo "[uhpc-salloc] Requesting a Slurm allocation (1 node)."
echo "[uhpc-salloc] NUM_SHELLS=$NUM_SHELLS"
echo "[uhpc-salloc] Forwarding extra Slurm options: ${EXTRA_ARGS[@]}"

# Request the allocation with --no-shell + forced -N1
ALLOCATION_OUTPUT=$(salloc --no-shell -N1 "${EXTRA_ARGS[@]}" 2>&1)

JOBID=$(echo "$ALLOCATION_OUTPUT" | grep "Granted job allocation" | awk '{print $4}')
if [ -z "$JOBID" ]; then
  echo "[uhpc-salloc] ERROR: Failed to parse job ID from salloc output."
  echo "$ALLOCATION_OUTPUT"
  exit 1
fi

echo "[uhpc-salloc] Successfully allocated job=$JOBID"
echo "[uhpc-salloc] Spawning $NUM_SHELLS shells..."

# Spawn multiple "interactive" steps. Each is a bash that just waits.
# We run them in the background, ignoring standard I/O for now.
for i in $(seq 1 "$NUM_SHELLS"); do
  STEP_NAME="shell$i"
  srun --jobid="$JOBID" --ntasks=1 -d singleton \
       --pty -J "$STEP_NAME" bash < /dev/null > /dev/null 2>&1 &
  echo "  [uhpc-salloc] Started step '$STEP_NAME' in background."
done

cat <<EOF

[uhpc-salloc] All shells are running under JobID $JOBID.

To attach to one of them, run e.g.:
  uhpc-login $JOBID 1   # attach to "shell1"
  uhpc-login $JOBID 2   # attach to "shell2"
... etc.

Once attached, you can run commands in that shell.
To "log off" but keep the shell alive, run 'uhpc-logoff' inside the attached shell.
Finally, when you are done with *all* shells, run:
  uhpc-unalloc $JOBID

This script will now background itself so you can close this terminal or log out,
and the allocation remains active.
EOF

# Instead of sleeping in foreground, do a "self-background" trick:
(
  nohup bash -c "while true; do sleep 3600; done" >/dev/null 2>&1 &
) &

disown -a  # Detach from all jobs
exit 0
